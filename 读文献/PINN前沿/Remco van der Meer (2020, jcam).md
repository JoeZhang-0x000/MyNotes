---
aliases:
  - Optimally weighted loss functions for solving PDEs with Neural Networks
---
## æ¦‚æ‹¬
1. æ–‡ç« è¯æ˜äº†For any linear PDEs,  the loss function is convex; however, it is still not clear about nonlinear PDEs.
2. æ–‡ç« è¯•å›¾æå‡ºä¸€ç§æ›´å…·ä¸€èˆ¬æ€§çš„loss functionï¼Œå¢åŠ äº†ä¸€ä¸ªå¹…åº¦å½’ä¸€åŒ–ï¼Œä½œè€…æè¿°è¯¥æ–¹æ³•å¯ä»¥åº”å¯¹å¯¼æ•°è¾ƒå¤§çš„é—®é¢˜ã€‚
>![[Pasted image 20231004162438.png]]![[Pasted image 20231004162344.png]]![[Pasted image 20231004162909.png]]
3. æ­¤å¤–ä½œè€…è¿˜æå‡ºä¸€ç§==è‡ªé€‚åº”é‡‡æ ·==æ–¹æ³•ï¼Œç”¨äºå¹³è¡¡è¾¹ç•Œå’ŒPDE residualï¼Œæ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼Œå¦‚æœBC residual >p* PDE residualï¼Œè¿™å°±è¯´æ˜å…¶ä¸­æœ‰ä¸€é¡¹è®­ç»ƒçš„ä¸å¥½ï¼Œé‚£ä¹ˆå°±éœ€è¦å¢åŠ å…¶é‡‡æ ·ç‚¹æ•°é‡ã€‚
	1. #idea è¿™ä¸æˆ‘ä»¬çš„é€æ¸å¢åŠ é‡‡æ ·ç‚¹çš„æ€è·¯ä¸è°‹è€Œåˆã€‚
## æ”¶è·
### å†™ä½œâœ
1. æ·±åº¦ç¥ç»ç½‘ç»œå·²ç»å‡ºç°äº†60å¤šå¹´äº†ï¼Œä½†æ˜¯ç›´åˆ°æœ€è¿‘æ‰å¯ä»¥åœ¨é€šç”¨è®¾å¤‡ä¸Šè¿›è¡Œè®­ç»ƒã€‚å‚è€ƒè‡ªDeep learning in neural networks: An overview (2014)ã€‚äºæ˜¯==This lead to exceptional achievements== in wide rage of problems, including ... ==Aside from these empirical achievements==, the ==theorical understanding== of such methods is also advancing rapidly. ==This has sparked interest== in ....
2. 
### PINNçš„ç†è§£
åŸæ–‡æåˆ°:
>so far, it is only clear that minimizing the loss functional exactly yields a solution of the PDE. However, when one minimizes the Monte-Carlo approximation instead, it is ==highly unlikely== that this exact minimum is attained.

1. ä½œè€…ä¸æˆ‘çš„æƒ³æ³•ä¸è°‹è€Œåˆï¼Œä½¿ç”¨Monte Claro ç§¯åˆ†åªèƒ½ä¿è¯åœ¨æœ‰é™ä¸ªç‚¹ä¸Šå¤„äºæœ€ä¼˜ï¼Œå› ä¸ºé‡‡æ ·ç‚¹çš„å½±å“ååˆ†å…³é”®ï¼Œå€˜è‹¥ä¸ç”¨Monte Claroç§¯åˆ†åˆ™å¯ä»¥è§„é¿é‡‡æ ·ç‚¹çš„é€‰å–é€ æˆçš„å½±å“ã€‚
	1. #idea é‚£ä¹ˆæˆ‘æ˜¯å¦å°±å¯ä»¥é‡‡å–ä¸€ç§æ›¿ä»£æ‰‹æ®µå»æ›´ç²¾ç¡®çš„è¡¨ç¤ºç§¯åˆ†ï¼Œæ¯”å¦‚æˆ‘ä¹‹å‰æƒ³åˆ°çš„ä¸‰è§’å½¢é«˜æ–¯ç§¯åˆ†ï¼Ÿæˆ–è®¸èƒ½æå‡ç²¾åº¦ï¼ŸğŸ¤”