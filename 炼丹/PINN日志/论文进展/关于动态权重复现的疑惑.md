## 动态权重
在Understanding and mitigating gradient pathologies in physics-informed neural networks这篇文章中，作者提出的一种动态权重算法。
![[Pasted image 20231012091513.png]]
可以看出，此算法是将PDE的权重设为1，BC\IC等其他辅助项的权重动态调整。具体俩说，首先计算出PDE损失的梯度的maximal_r，然后分别对BC\IC中每一项都计算梯度的mean_i，于是对于该项，其权重值可以更新为计算maximal_r/mean_i，然后取一个滑动平均的值。
这里的核心思想是要调整多项之间的收敛速度。作者在另外一篇文献 (When and why PINNs fail to train: A neural tangent kernel perspective) 中提到，根据他的观察与计算，PDE的NTK矩阵的特征值 K-rr(特征值越大，收敛的越快) 比K_uu (其他项) 在数量级上要大很多，因此导致了训练的不协调。
![[Pasted image 20231012092656.png]]
所以动态权重是为了通过对梯度的统计，平衡损失函数中各项之间的收敛速度 (也有其他文章的思路与本文中讨论的不太一样，比如放大关键权重) 。
## 原文代码
[原文Helmholtz代码](https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs/blob/master/Helmholtz/Helmholtz2D_model_tf.py#L306)
最开始比较疑惑的点在于，原文中的$\theta$到底是指神经网络中的所有参数，还是每一层，还是每一个神经元？在查看了作者的源代码后，我认为是对全部的参数进行的操作。
原文代码中写到：
![[Pasted image 20231012094331.png]]
这里很明显的只维护了一个持久化的权重值，即``self.adaptive_constant_val``.
另外，再看作者是如何存储并计算最大值和平均值的：
![[Pasted image 20231012094618.png]]
这一段代码利用反向传播计算梯度之后保存再两个临时的列表中，然后，
![[Pasted image 20231012094630.png]]
根据上面这段代码，作者计算的确实是整体梯度的最大值和平均值，并不是局部的。
## 我的复现
```
我在复现时，关键部分代码如下：
```python
        # 获取梯度

        for enum,(dataloader,loss_fn) in enumerate(zip(dataloaders,loss_fns)):

            loss_item = torch.zeros([1]).to(device)

            optimizer.zero_grad()

            loss_item = torch.zeros([1]).to(device)

            for data,target in  dataloader:

                data,target = data.to(device),target.to(device)

                loss_item += loss_fn(model,(data,target))

            # print('------')

            loss_item.backward()

            gradients = abs(np.hstack([param.grad.view(-1) for param in model.parameters()]))

            grad_max = gradients.max()

            grad_mean = gradients.mean()

            # 动态计算权重

            if enum == 0:

                grad_r_max = grad_max

                grad_r_mean = grad_mean

            else:

                lambda_bar = grad_r_mean/grad_mean

                lambda_i = (1-ALPHA)*lambda_bar+ALPHA*lambda_bar

                loss_weights[enum] = lambda_i
```
其中，
```python
gradients = abs(np.hstack([param.grad.view(-1) for param in model.parameters()]))
```
这里是将神经网络的所有参数的梯度全部记录在gradients中，然后分别取了其maximal, mean. 
```python
lambda_bar = grad_r_mean/grad_mean

lambda_i = (1-ALPHA)*lambda_bar+ALPHA*lambda_bar
```
如果取到的是PDE的损失，保存在一个持久变量中，若取到的是其他项的损失，则计算其新的权重。
如果我的理解没有错，那么这段代码应该是原文所想表达的意思。

于是我进行了一个简单的实验，如果要拟合正弦函数。
$$
u = \sin(\pi x),\qquad x \in [-5,5]
$$
我分别做了三组实验，对照组 (不使用动态权重)，M1组 (使用maximal)，M2组 (使用mean)，其结果如下 (图片左上方为L2误差)：



![[Pasted image 20231012100111.png|对照组|300]]![[Pasted image 20231012100237.png|M1|300]]![[Pasted image 20231012100409.png|M2|300]]
可以看出，对照组的结果最好。当然可能是因为本文讨论的中动态权重算法主要是为了应对复杂边界的，所以在简单例子中表现不好。但是，值得注意的是，M1组的效果十分差。然而原文中却推荐的是M1组所用的通过最大值计算的权重算法，并且原文对于Helmholtz方程的求解确实也取得了良好的提升。

但是在研究burgers方程时，使用了M2组的方法却出现了这种怪异的现象，即BC和IC两项的权重全都衰减到0了，我想这是因为PDE的梯度均值接近0了。或许应该找一个更好的度量方法，或者对他们做一个映射，使得不会降低到0，至少要有一个饱和区，使得其不会无限增大也不会太小。
![[Pasted image 20231012102505.png|loss weights of burgers equation via M2]]
