## Experiment Setup
This experiment focuses on determining the suitable distribution of the loose factor, denoted as $t$, in our study. Previous findings suggested that the *exponential* distribution often yielded optimal performance, while recent experiments revealed that the *logarithmic* distribution could be more effective in certain scenarios.

The experiment is divided into three key parts to thoroughly assess the impact of the loose factor distribution:

1. Influence of Auxiliary Data: This part examines the effects of auxiliary data when it is close to or far from the ground truth. By comparing the performance under these two conditions, we can gain insights into the effectiveness of different distributions in handling varying degrees of discrepancy between auxiliary and actual data.

2. Influence of Training Steps: Building on previous observations, this part investigates the relationship between the number of training steps and the resulting R2 score curves. Although initial increases followed by decreases in the slope of the curves were observed, it is important to recognize that longer training durations may not always lead to improved performance. Thus, this segment explores the optimal duration for effective training.

3. Influence of Number of Segments: This section explores the impact of segmenting the loose factor curve on its smoothness. Specifically, we aim to determine whether smoother curves result in higher precision. It is worth noting that, with a fixed total number of training steps, a smoother curve implies a reduction in the number of training steps per segment.

By conducting this experiment, we aim to identify the optimal distribution of the loose factor in our study. Through the investigation of auxiliary data, training steps, and the number of segments, we can gain valuable insights into the most effective approaches for achieving precise and reliable results. The findings from this experiment will contribute to the development of improved methodologies in related research fields.

## Experiment Results

| Option | Parameters                                    | Cost Time | R2 Score |
|--------|-----------------------------------------------|-----------|----------|
| 2      | Re: 100, A_Re: 10, pde_n: 9000, bc_n: 1000     | 18254.27  | 0.65     |
| 1      | Re: 100, A_Re: 10, pde_n: 9000, bc_n: 1000     | 18217.57  | -0.89    |
| 3      | Re: 100, A_Re: 10, pde_n: 9000, bc_n: 1000     | 18129.20  | -3.23    |
| 0      | Re: 100, A_Re: 10, pde_n: 9000, bc_n: 1000     | 18253.05  | -9.28    |

| Option | Parameters                               | Cost Time | R2 Score |
|--------|------------------------------------------|-----------|----------|
| 2      | Re: 100, A_Re: 50, pde_n: 9000, bc_n: 1000 | 18596.80  | 0.96     |
| 1      | Re: 100, A_Re: 50, pde_n: 9000, bc_n: 1000 | 18569.11  | 0.89     |
| 3      | Re: 100, A_Re: 50, pde_n: 9000, bc_n: 1000 | 18577.80  | -1.67    |
| 0      | Re: 100, A_Re: 50, pde_n: 9000, bc_n: 1000 | 18587.40  | -13.15   |

## Results Analysis
It is obviously that option 2 outperform the others in our experiments, irrespective of the auxiliary data. 