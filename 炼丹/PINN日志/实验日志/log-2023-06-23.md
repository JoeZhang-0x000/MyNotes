## Experiment Result
This experiment delves into the realm of coarse-fine sampling techniques. In our previous investigation, the neural network was trained for 50k steps, divided into 10 segments. Notably, we discovered that gradually increasing both interior and boundary samplings from zero resulted in the best performance. However, alternative approaches exhibited poor results. At the time, we hypothesized that the limited training duration of 5k steps per segment hindered convergence. Consequently, we embarked on this experiment, extending the training duration to 100k steps across the same 10 segments. Unexpectedly, the outcome proved to be even more unfavorable. Here, we present the key findings supported by illustrative figures.
![[Pasted image 20230623192346.png]]